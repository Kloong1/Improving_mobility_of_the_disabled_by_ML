{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CNN_spectrogram_model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"code","metadata":{"id":"swJHuInPdw2_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630386543712,"user_tz":-540,"elapsed":19235,"user":{"displayName":"­김요환 | 서울 컴퓨터소프트웨어학부","photoUrl":"","userId":"11238218588459355967"}},"outputId":"179aa67c-c063-44fb-d075-98937168ec33"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dhj8IERwwEr7"},"source":["import os\n","import numpy as np\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8i5DIMyo0ux7"},"source":["basicpath = '/content/drive/Shareddrives/Project/CNN_spectrogram_our_dataset/spectrograms'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mDGxwS1Vx6Cb"},"source":["# 모든 position generator"]},{"cell_type":"code","metadata":{"id":"sMM6CNGsJqpg"},"source":["def image_pos_gen_list(datapath, batch_size):\n","\n","  pos_gen_list = list()\n","  datagen = ImageDataGenerator(rescale=1.0/255)\n","\n","  positions = os.listdir(datapath)\n","  for pos in positions:\n","    pos_path = os.path.join(datapath, pos)\n","    batch_size_pos = batch_size // len(positions)\n","    print(pos_path)\n","    print(f'batch size: {batch_size_pos}')\n","    pos_gen = datagen.flow_from_directory(pos_path, target_size=(48,48), batch_size=batch_size_pos)\n","    pos_gen_list.append(pos_gen)\n","  \n","  return pos_gen_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wZhX1j0WhH4"},"source":["def image_pos_generator(img_pos_gen_list):\n","  while True:  \n","    batch_label_pairs = [ img_pos_gen.next() for img_pos_gen in img_pos_gen_list ]\n","\n","    batches = list()\n","    labels = list()\n","\n","    for batch, label in batch_label_pairs:\n","      batches.append(batch)\n","      labels.append(label)\n","\n","    batch_size, width, height, channel = batches[0].shape\n","    batch_size, classes = labels[0].shape\n","    \n","    batch_concat = np.empty((batch_size * len(batches), width, height, channel))\n","    label_concat = np.empty((batch_size * len(labels), classes))\n","\n","    for i, (batch, label) in enumerate(zip(batches, labels)):\n","      batch_concat[batch_size * i : batch_size * (i + 1)] = batches[i]\n","      label_concat[batch_size * i : batch_size * (i + 1)] = labels[i]\n","\n","    yield batch_concat, label_concat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3VAdfBzVI7T"},"source":["trainpath = os.path.join(basicpath, 'train')\n","valpath = os.path.join(basicpath, 'val')\n","testpath = os.path.join(basicpath, 'test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oai9Fz0uyhEw"},"source":["batch_size = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9lX_lv5U_cv"},"source":["train_pos_gen_list = image_pos_gen_list(trainpath, batch_size)\n","val_pos_gen_list = image_pos_gen_list(valpath, batch_size)\n","test_pos_gen_list = image_pos_gen_list(testpath, batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYrr8iZ5Sgic"},"source":["train_gen = image_pos_generator(train_pos_gen_list)\n","val_gen = image_pos_generator(val_pos_gen_list)\n","test_gen = image_pos_generator(test_pos_gen_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JFDZzDpnyDcI"},"source":["# Pocket position generator"]},{"cell_type":"code","metadata":{"id":"w7Ws9mQ0HyOF"},"source":["trainpath = os.path.join(basicpath, 'train', 'Pocket')\n","valpath = os.path.join(basicpath, 'val', 'Pocket')\n","testpath = os.path.join(basicpath, 'test', 'Pocket')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sh0Y23vxy0a-"},"source":["train_datagen = ImageDataGenerator(rescale=1.0/255)\n","val_datagen = ImageDataGenerator(rescale=1.0/255)\n","test_datagen = ImageDataGenerator(rescale=1.0/255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3b03zRSMxYaa"},"source":["classes = ['bus', 'car', 'metro', 'powerChar', 'still', 'walking' ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIM100vxyjZy"},"source":["batch_size = 26"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"StEZcDAO1EaU"},"source":["train_gen = train_datagen.flow_from_directory(trainpath, target_size=(48,48), batch_size=batch_size, classes=classes)\n","val_gen = val_datagen.flow_from_directory(valpath, target_size=(48,48), batch_size=batch_size, classes=classes)\n","test_gen = test_datagen.flow_from_directory(testpath, target_size=(48,48), batch_size=batch_size, classes=classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8IunCzybwsI3"},"source":["steps_per_epoch = int(2640/ batch_size)\n","validation_steps = int(286 / batch_size)\n","test_steps = int(286 / batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLTPz5tpvIdG"},"source":["train_gen.class_indices"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HDt7vtiokeAl"},"source":["# F1-score"]},{"cell_type":"code","metadata":{"id":"7OxX5IfBkeT3"},"source":["from keras import backend as K\n","\n","def recall(y_target, y_pred):\n","    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n","    # round : 반올림한다\n","    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n","    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n","\n","    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n","    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n","\n","    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n","    count_true_positive_false_negative = K.sum(y_target_yn)\n","\n","    # Recall =  (True Positive) / (True Positive + False Negative)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n","\n","    # return a single tensor value\n","    return recall\n","\n","\n","def precision(y_target, y_pred):\n","    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n","    # round : 반올림한다\n","    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n","    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n","\n","    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n","    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n","\n","    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n","    count_true_positive_false_positive = K.sum(y_pred_yn)\n","\n","    # Precision = (True Positive) / (True Positive + False Positive)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n","\n","    # return a single tensor value\n","    return precision\n","\n","\n","def f1score(y_target, y_pred):\n","    _recall = recall(y_target, y_pred)\n","    _precision = precision(y_target, y_pred)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n","    \n","    # return a single tensor value\n","    return _f1score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2MeddQipzPZQ"},"source":["# 모델 정의"]},{"cell_type":"code","metadata":{"id":"bi9X-W0v0oYn"},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","from keras import optimizers\n","\n","model = Sequential()\n","model.add(Conv2D(16, (3,3), activation='relu', input_shape = (48, 48, 3), padding='same'))\n","model.add(MaxPooling2D((2,2)))\n","model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2,2)))\n","model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2,2)))\n","\n","model.add(Flatten())\n","model.add(Dropout(0.25))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(classes), activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HpNZ5iR7kNc"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_iBlB9vzHfu"},"source":["# Callback 함수"]},{"cell_type":"code","metadata":{"id":"eJZFjanPQPob"},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","es = EarlyStopping(monitor='val_loss', patience=8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZrGC6Vo8WCm"},"source":["basicpath_cp = '/content/drive/Shareddrives/Project/CNN_spectrogram_our_dataset/cp/05'\n","cp_path = os.path.join(basicpath_cp, 'pocket_{epoch}.ckpt')\n","cp = ModelCheckpoint(cp_path, monitor='val_loss', save_best_only=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D7XiSpVR-g0_"},"source":["lr_schedule = keras.optimizer_v2.learning_rate_schedule.ExponentialDecay(initial_learning_rate=0.001, decay_steps=steps_per_epoch * 4, decay_rate=0.8, staircase=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X5Etvbf9zJlH"},"source":["# 모델 학습"]},{"cell_type":"code","metadata":{"id":"5ciIWFBSF6kl"},"source":["model.compile(optimizer=keras.optimizer_v2.adam.Adam(learning_rate=lr_schedule),\n","              loss='categorical_crossentropy',\n","              metrics=['acc', f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ohZ9wbS0qkg"},"source":["history = model.fit_generator(train_gen,\n","                              steps_per_epoch=steps_per_epoch,\n","                              epochs=100,\n","                              validation_data=val_gen,\n","                              validation_steps=validation_steps,\n","                              callbacks=[es, cp])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQY2XzM0ihbX"},"source":["# Plotting"]},{"cell_type":"code","metadata":{"id":"WotPc7r5ttvU"},"source":["import matplotlib.pyplot as plt\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(loss) + 1)  #1~20\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()\n","\n","plt.clf()\n","\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and Validation Acc')\n","plt.xlabel('Epoch')\n","plt.ylabel('Acc')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oRPt2aaigwoa"},"source":["# 평가"]},{"cell_type":"code","metadata":{"id":"VIzLqtzOgwDr"},"source":["for cp in os.listdir(basicpath_cp):\n","  print(cp)\n","  epoch = int(cp.split(sep='_')[1].split(sep='.')[0])\n","  if epoch < 15:\n","    print('pass')\n","    continue\n","  model.load_weights(os.path.join(basicpath_cp, cp))\n","  score = model.evaluate_generator(test_gen, steps=test_steps)\n","  print(f'Test loss: {score[0]}, Test acc: {score[1]}, Test f1-score: {score[2]}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"320Kzdxt0YEx"},"source":["# Confusion matrix 생성"]},{"cell_type":"code","metadata":{"id":"xjibYprNRJHr"},"source":["model.load_weights(os.path.join(basicpath_cp, 'pocket_29.ckpt' ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PyHi6qpD0Zw2"},"source":["import matplotlib.pyplot as plt\n","import itertools\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","  plt.title(title)\n","  plt.colorbar()\n","  tick_marks=np.arange(len(classes))\n","  plt.xticks(tick_marks, classes, rotation=45)\n","  plt.yticks(tick_marks, classes)\n","  \n","  if normalize:\n","    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","      \n","  thresh = cm.max() / 2.\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","  \n","  plt.tight_layout()\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GItDhmpF18bV"},"source":["def make_test_batch(test_gen, step):\n","  batches = list()\n","  labels = list()\n","\n","  for i in range(step):\n","    batch, label = next(test_gen)\n","    batches.append(batch)\n","    labels.append(label)\n","  \n","  batch_size, width, height, channel = batches[0].shape\n","  batch_size, classes = labels[0].shape\n","\n","  batch_concat = np.empty((batch_size * len(batches), width, height, channel))\n","  label_concat = np.empty((batch_size * len(batches), classes))\n","\n","  for i, (batch, label) in enumerate(zip(batches, labels)):\n","    batch_concat[batch_size * i : batch_size * (i + 1)] = batches[i]\n","    label_concat[batch_size * i : batch_size * (i + 1)] = labels[i]\n","  \n","  return batch_concat, label_concat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V6yAb34s5nlx"},"source":["X, Y = make_test_batch(test_gen, step=test_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EkJGoLFWivY4"},"source":["X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRbVaEw81GG_"},"source":["# Predict the values from the validation dataset\n","Y_pred = model.predict(X)\n","# Convert predictions classes to one hot vectors\n","Y_pred_classes = np.argmax(Y_pred, axis = 1)\n","# Convert validation observations to one hot vectors\n","Y_true = np.argmax(Y, axis = 1)\n","# compute the confusion matrix\n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n","# plot the confusion matrix\n","plot_confusion_matrix(confusion_mtx, classes = classes)"],"execution_count":null,"outputs":[]}]}